<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Details | Deepthi Sudharsan</title>
    <link rel="stylesheet" href="styles.css">
    <link
        href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600&family=Playfair+Display:ital,wght@0,600;1,600&display=swap"
        rel="stylesheet">
    <style>
        .page-container {
            max-width: 800px;
            margin: 0 auto;
            padding: 100px 20px;
            text-align: left;
        }

        /* Enable scrolling for this page */
        body {
            overflow-y: auto !important;
            height: auto !important;
        }

        .back-btn {
            display: inline-block;
            margin-bottom: 2rem;
            color: #888;
            text-decoration: none;
            font-size: 0.9rem;
            transition: color 0.3s;
        }

        .back-btn:hover {
            color: var(--accent-color);
        }

        h1 {
            font-family: 'Playfair Display', serif;
            font-size: 3rem;
            margin-bottom: 2rem;
            color: white;
            text-transform: capitalize;
        }

        .content-section {
            margin-bottom: 2rem;
        }

        .content-section h3 {
            font-family: 'Inter', sans-serif;
            font-size: 1.5rem;
            color: var(--accent-color);
            margin-bottom: 1rem;
        }

        p {
            line-height: 1.8;
            color: #ccc;
            margin-bottom: 1.5rem;
            font-size: 1.1rem;
        }

        ul {
            list-style: none;
            padding: 0;
        }

        li {
            margin-bottom: 1rem;
            padding-left: 1.5rem;
            position: relative;
            color: #ccc;
            line-height: 1.6;
        }

        li::before {
            content: 'â€¢';
            color: var(--accent-color);
            position: absolute;
            left: 0;
            font-size: 1.2rem;
        }

        a {
            color: #fff;
            text-decoration: underline;
            text-decoration-color: var(--accent-color);
        }

        /* Papers Section Styles */
        .paper-card {
            background: rgba(255, 255, 255, 0.05);
            border: 1px solid rgba(255, 255, 255, 0.1);
            border-radius: 12px;
            padding: 1.5rem;
            margin-bottom: 1.5rem;
            transition: transform 0.2s, background 0.2s;
        }

        .paper-card:hover {
            background: rgba(255, 255, 255, 0.08);
            transform: translateY(-2px);
        }

        .paper-header {
            margin-bottom: 0.5rem;
        }

        .paper-title {
            font-family: 'Inter', sans-serif;
            font-size: 1.2rem;
            font-weight: 600;
            color: #fff;
            margin: 0;
            line-height: 1.4;
        }

        .paper-year {
            font-weight: 400;
            color: var(--accent-color);
            margin-left: 0.5rem;
            font-size: 0.9em;
        }

        .paper-tldr {
            font-size: 1rem;
            color: #ddd;
            margin-bottom: 1rem;
            font-style: italic;
        }

        .paper-abstract-container {
            background: rgba(0, 0, 0, 0.3);
            padding: 1rem;
            border-radius: 8px;
            margin-bottom: 1rem;
            border-left: 2px solid var(--accent-color);
        }

        .paper-abstract {
            font-size: 0.95rem;
            color: #bbb;
            margin: 0;
            line-height: 1.6;
        }

        .paper-actions {
            display: flex;
            gap: 1rem;
            flex-wrap: wrap;
        }

        .action-btn {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            background: transparent;
            border: 1px solid #555;
            border-radius: 6px;
            color: #ccc;
            font-size: 0.9rem;
            cursor: pointer;
            transition: all 0.2s;
            text-decoration: none;
            font-family: 'Inter', sans-serif;
        }

        .action-btn:hover {
            border-color: var(--accent-color);
            color: #fff;
            background: rgba(255, 215, 0, 0.1);
        }

        .link-btn {
            text-decoration: none;
            /* Override default a underline */
        }
    </style>
</head>

<body>
    <div class="page-container">
        <a href="index.html" class="back-btn">&larr; Back to Home</a>
        <h1 id="pageTitle">Loading...</h1>
        <div id="content">
            <!-- Dynamic Content will be injected here -->
        </div>

        <!-- Contact Section (Common Footer) -->
        <div style="margin-top: 5rem; padding-top: 3rem; border-top: 1px solid #333; text-align: center;">
            <h2 style="font-family: 'Playfair Display', serif; font-size: 2rem; margin-bottom: 1rem; color: #fff;">Get
                In Touch</h2>
            <p style="color: #888; margin-bottom: 2rem;">Open for collaborations, speaking opportunities, and coffee
                chats.</p>
            <a href="mailto:hello@deepthi.com" style="
                display: inline-block;
                padding: 1rem 3rem;
                border: 1px solid #fff;
                color: #fff;
                text-decoration: none;
                text-transform: uppercase;
                letter-spacing: 2px;
                transition: all 0.3s;" onmouseover="this.style.background='#fff'; this.style.color='#000';"
                onmouseout="this.style.background='transparent'; this.style.color='#fff';">Say Hello</a>
        </div>
    </div>

    <script>
        const params = new URLSearchParams(window.location.search);
        const titleKey = (params.get('title') || 'Details').toUpperCase();

        const titleDisplay = params.get('title') || 'Details';
        document.getElementById('pageTitle').innerText = titleDisplay;
        document.title = `${titleDisplay} | Deepthi Sudharsan`;

        // Papers Data
        const papersData = [
            {
                title: "Agentic Framework for Culturally Grounded Visual Story Generation",
                year: 2026,
                venue: "AAAI EGSAI 2026",
                authors: "Hamna, Aasim Baig, Aayush Jansari, Deepthi Sudharsan, Advait Bhat, Vivek Seshadri, Safiya F Husain, Mohit Jain, Kalika Bali",
                tldr: "Proposed an agentic, human-in-the-loop framework for generating culturally grounded visual stories using coordinated LLM agents and text-to-image models, enabling coherent, character-consistent, and community-aligned story-based learning for learners in the Global South.",
                abstract: "Proposed an agentic, human-in-the-loop framework for generating culturally grounded visual stories using coordinated LLM agents and text-to-image models, enabling coherent, character-consistent, and community-aligned story-based learning for learners in the Global South.",
                citation: "Hamna, et al. (2026). Agentic Framework for Culturally Grounded Visual Story Generation. AAAI EGSAI 2026.",
                link: ""
            },
            {
                title: "The Role of Synthetic Data in Multilingual, Multicultural AI systems: Lessons from Indic languages",
                year: 2025,
                venue: "Preprint",
                authors: "Pranjal A Chitale, Varun Gumma, Sanchit Ahuja, Prashant Kodali, Manan Uppadhyay, Deepthi Sudharsan, Sunayana Sitaram",
                tldr: "In this work, we present Updesh, a synthetic instruction-tuning dataset for Indian languages built via a culturally grounded, bottom-up approach. Evaluations show limits of LLM-as-judge and highlight both the promise and constraints of synthetic multilingual data.",
                abstract: "In this work, we present Updesh, a synthetic instruction-tuning dataset for Indian languages built via a culturally grounded, bottom-up approach. Evaluations show limits of LLM-as-judge and highlight both the promise and constraints of synthetic multilingual data.",
                citation: "Chitale, P. A., et al. (2025). The role of synthetic data in Multilingual, Multi-cultural AI systems: Lessons from Indic Languages. arXiv:2509.21294.",
                link: "https://arxiv.org/pdf/2509.21294",
                huggingface_link: "https://huggingface.co/datasets/microsoft/Updesh_beta",
                aikosh_link: "https://aikosh.indiaai.gov.in/home/datasets/details/updesh.html"
            },
            {
                title: "Towards a Community-Centric Approach to Measuring Cultural Representation in AI Image Generation: Lessons from Two Case Studies",
                year: 2025,
                venue: "Under Review",
                authors: "Nari Johnson, Deepthi Sudharsan, Hamna, Samantha Dalal, Theo Holroyd, Anja Thieme, Hoda Heidari, Daniela Massiceti, Jennifer Wortman Vaughan, Cecily Morrison",
                tldr: "This paper argues that AI measurement often ignores the perspectives of impacted communities. Focusing on “cultural appropriateness” in text-to-image models, we worked with blind/low vision individuals in the UK and residents from two Indian states. By involving these communities in defining what should be measured, they showed how lived experience can shape more meaningful metrics. The work highlights opportunities for HCI research to embed community expertise into measuring generative AI systems.",
                abstract: "This paper argues that AI measurement often ignores the perspectives of impacted communities. Focusing on “cultural appropriateness” in text-to-image models, we worked with blind/low vision individuals in the UK and residents from two Indian states. By involving these communities in defining what should be measured, they showed how lived experience can shape more meaningful metrics. The work highlights opportunities for HCI research to embed community expertise into measuring generative AI systems.",
                citation: "Johnson, N., et al. (2025). Towards a Community-Centric Approach to Measuring Cultural Representation in AI Image Generation. Under Review.",
                link: ""
            },
            {
                title: "Position: To Make Text-to-Image Models that Work for Marginalized Communities, We Need New Measurement Practices for the Long Tail",
                year: 2025,
                venue: "Preprint",
                authors: "Nari Johnson, Hamna, Deepthi Sudharsan, Theo Holroyd, Samantha Dalal, Siobhan Mackenzie Hall, Jennifer Wortman Vaughan, Daniela Massiceti, Cecily Morrison",
                tldr: "Current text-to-image (T2I) evaluation metrics fail to capture the accuracy of low-resource, culturally specific concepts important to marginalized communities. This paper highlights challenges in validating these metrics using two community-based case studies, revealing issues like the need for community knowledge and difficulty in capturing nuanced image quality. It calls for new, community-centered measurement methods tailored to long-tail concepts.",
                abstract: "Current text-to-image (T2I) evaluation metrics fail to capture the accuracy of low-resource, culturally specific concepts important to marginalized communities. This paper highlights challenges in validating these metrics using two community-based case studies, revealing issues like the need for community knowledge and difficulty in capturing nuanced image quality. It calls for new, community-centered measurement methods tailored to long-tail concepts.",
                citation: "Johnson, N., et al. (2025). Position: To Make Text-to-Image Models that Work for Marginalized Communities. Preprint.",
                link: "https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/longtail.pdf"
            },
            {
                title: "ELR-1000: A Community-Generated Dataset for Endangered Indic Indigenous Languages",
                year: 2025,
                venue: "IJCNLP - AACL 2025",
                authors: "Neha Joshi, Pamir Gogoi, Aasim Mirza, Aayush Jansari, Aditya Yadavalli, Ayushi Pandey, Arunima Shukla, Deepthi Sudharsan, Kalika Bali, Vivek Seshadri",
                tldr: "In this work, we propose our ELR-1000 benchmark dataset, which contains 1,060 traditional recipes from rural Eastern India in 10 endangered languages, collected via a mobile tool for low-digital-literacy contributors. It evaluates LLM translation performance, showing that cultural and low-resource contexts remain challenging, but targeted background/context greatly improves results. The dataset is released to promote equitable, culturally aware language technologies.",
                abstract: "In this work, we propose our ELR-1000 benchmark dataset, which contains 1,060 traditional recipes from rural Eastern India in 10 endangered languages, collected via a mobile tool for low-digital-literacy contributors. It evaluates LLM translation performance, showing that cultural and low-resource contexts remain challenging, but targeted background/context greatly improves results. The dataset is released to promote equitable, culturally aware language technologies.",
                citation: "Joshi, N., et al. (2025). ELR-1000: A Community-Generated Dataset for Endangered Indic Indigenous Languages. IJCNLP - AACL 2025.",
                link: "https://www.arxiv.org/pdf/2512.01077"
            },
            {
                title: "What’s Not on the Plate? Rethinking Food Computing through Indigenous Indian Datasets",
                year: 2025,
                venue: "MMFood 2025",
                authors: "Pamir Gogoi, Neha Joshi, Ayushi Pandey, Deepthi Sudharsan, Saransh Kumar Gupta, Lipika Dey, Partha Pratim Das, Kalika Bali and Vivek Seshadri",
                tldr: "A multimodal dataset of 1000 indigenous recipes from 10 endangered language communities in rural India was collected using the Karya app. Featuring texts, images, and audios contributed by first-time digital workers, this work promotes culturally inclusive, community-authored data for AI. It advances ethical, scalable food computing and opens pathways in cultural AI, public health, and sustainable agriculture.",
                abstract: "A multimodal dataset of 1000 indigenous recipes from 10 endangered language communities in rural India was collected using the Karya app. Featuring texts, images, and audios contributed by first-time digital workers, this work promotes culturally inclusive, community-authored data for AI. It advances ethical, scalable food computing and opens pathways in cultural AI, public health, and sustainable agriculture.",
                citation: "Gogoi, P., et al. (2025). What’s Not on the Plate? Rethinking Food Computing through Indigenous Indian Datasets. MMFood 2025.",
                link: "https://dl.acm.org/doi/10.1145/3746264.3760498"
            },
            {
                title: "KAHANI: Culturally-Nuanced Visual Storytelling Pipeline for Non-Western Cultures",
                year: 2025,
                venue: "COMPASS 2025",
                authors: "Hamna, Deepthi Sudharsan, Agrima Seth, Ritvik Budhiraja, Deepika Khullar, Vyshak Jain, Kalika Bali, Aditya Vashistha, Sameer Segal",
                tldr: "Developed Kahani, a culturally-nuanced visual storytelling tool utilizing GPT-4 Turbo and Stable Diffusion XL (SDXL) with Chain of Thought (CoT) prompting, to generate culturally nuanced visual stories for non-Western cultures. Our tool outperformed ChatGPT-4 (with DALL-E3) in 27 out of 36 user comparisons for cultural relevance and specificity.",
                abstract: "Developed Kahani, a culturally-nuanced visual storytelling tool utilizing GPT-4 Turbo and Stable Diffusion XL (SDXL) with Chain of Thought (CoT) prompting, to generate culturally nuanced visual stories for non-Western cultures. Our tool outperformed ChatGPT-4 (with DALL-E3) in 27 out of 36 user comparisons for cultural relevance and specificity.",
                citation: "Hamna, et al. (2025). KAHANI: Culturally-Nuanced Visual Storytelling Pipeline for Non-Western Cultures. COMPASS 2025.",
                link: "https://dl.acm.org/doi/10.1145/3715335.3735478"
            },
            {
                title: "Coconut Tree Detection using Deep Learning Models",
                year: 2022,
                venue: "DA&CI 2022",
                authors: "Deepthi Sudharsan, K. Harish, U. Asmitha, S. Roshan Tushar, H. Theivaprakasham, V. Sowmya, V. V. Sajith Variyar, Krishnamoorthy Deva Kumar, Vinayakumar Ravi",
                tldr: "Implemented and optimized object detection models (Faster RCNN, DETR, YOLOv5, RetinaNet, VFNet) with the help of IceVision framework for coconut tree detection and segmentation after experimenting with training these object detection models on low and high-resolution datasets.",
                abstract: "Implemented and optimized object detection models (Faster RCNN, DETR, YOLOv5, RetinaNet, VFNet) with the help of IceVision framework for coconut tree detection and segmentation after experimenting with training these object detection models on low and high-resolution datasets.",
                citation: "Sudharsan, D., et al. (2022). Coconut Tree Detection Using Deep Learning Models. DA&CI 2022.",
                link: "https://www.researchgate.net/publication/374256540_Coconut_Tree_Detection_Using_Deep_Learning_Models"
            },
            {
                title: "Analysis of Machine Learning and Deep Learning Algorithms for Detection of Brain Disorders Using MRI Data",
                year: 2021,
                venue: "ISCMM 2021",
                authors: "Deepthi Sudharsan, S Isha Indhu, Kavya S Kumar, Lakshaya Karthikeyan, L Srividhya, V Sowmya, EA Gopalakrishnan, KP Soman",
                tldr: "Developed and evaluated Machine Learning and Deep Learning models (SVM, Decision Tree, Random Forest, Gaussian Naive Bayes, 1D-CNN) for the preemptive diagnosis of Schizophrenia (Kaggle dataset) and Alzheimer's (TADPOLE dataset) using MRI features. In this work, we achieved optimized classification performance, with Gaussian Naive Bayes excelling in Schizophrenia detection and Random Forest in Alzheimer's.",
                abstract: "Developed and evaluated Machine Learning and Deep Learning models (SVM, Decision Tree, Random Forest, Gaussian Naive Bayes, 1D-CNN) for the preemptive diagnosis of Schizophrenia (Kaggle dataset) and Alzheimer's (TADPOLE dataset) using MRI features. In this work, we achieved optimized classification performance, with Gaussian Naive Bayes excelling in Schizophrenia detection and Random Forest in Alzheimer's.",
                citation: "Sudharsan, D., et al. (2021). Analysis of Machine Learning and Deep Learning Algorithms for Detection of Brain Disorders Using MRI Data. ISCMM 2021.",
                link: "https://link.springer.com/chapter/10.1007/978-981-19-0151-5_4"
            },
            {
                title: "DistilRoBERTa Based Sentence Embedding for Rhetorical Role Labelling of Legal Case Documents",
                year: 2021,
                venue: "FIRE 2021",
                authors: "Deepthi Sudharsan, U Asmitha, B Premjith, KP Soman",
                tldr: "Contributed to the AILA 2021 shared task by implementing an Artificial Neural Network (ANN) for automated rhetorical role assignment in legal documents. This solution achieved 85.18% validation accuracy and 30.9% testing precision, demonstrating a practical approach to enhance information retrieval and systematic organization in the Indian legal system.",
                abstract: "Contributed to the AILA 2021 shared task by implementing an Artificial Neural Network (ANN) for automated rhetorical role assignment in legal documents. This solution achieved 85.18% validation accuracy and 30.9% testing precision, demonstrating a practical approach to enhance information retrieval and systematic organization in the Indian legal system.",
                citation: "Sudharsan, D., et al. (2021). DistilRoBERTa Based Sentence Embedding for Rhetorical Role Labelling of Legal Case Documents. FIRE 2021.",
                link: "https://ceur-ws.org/Vol-3159/T2-3.pdf"
            }
        ];

        // Helper to generate Papers HTML
        function generatePapersHTML() {
            // Sort by year (descending) just in case, though they are already sorted
            const sortedPapers = papersData.sort((a, b) => b.year - a.year);

            return `
                <div class="content-section">
                    <h3>Research</h3>
                    <div class="papers-list">
                        ${sortedPapers.map((paper, index) => `
                            <div class="paper-card">
                                <div class="paper-header">
                                    <h4 class="paper-title">${paper.title}</h4>
                                    <span class="paper-venue" style="display:block; font-size: 0.9em; font-weight: normal; color: #ffeb3b; margin-top: 4px;">${paper.venue}</span>
                                    <div class="paper-authors" style="font-size: 0.85rem; color: #aaa; margin-top: 4px;">${paper.authors}</div>
                                </div>
                                <p class="paper-tldr"><strong>TL;DR:</strong> ${paper.tldr}</p>
                                
                                <div class="paper-abstract-container" id="abstract-${index}" style="display: none;">
                                    <p class="paper-abstract">${paper.abstract}</p>
                                </div>

                                <div class="paper-actions">
                                    <button class="action-btn" onclick="copyCitation('${index}')">
                                        <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect><path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path></svg>
                                        Copy Citation
                                    </button>
                                    <button class="action-btn" onclick="toggleAbstract('${index}')">
                                        <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M2 3h6a4 4 0 0 1 4 4v14a3 3 0 0 0-3-3H2z"></path><path d="M22 3h-6a4 4 0 0 0-4 4v14a3 3 0 0 1 3-3h7z"></path></svg>
                                        Read Abstract
                                    </button>
                                    ${paper.link ? `<a href="${paper.link}" target="_blank" class="action-btn link-btn">
                                        <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line></svg>
                                        View Paper
                                    </a>` : ''}
                                    ${paper.huggingface_link ? `<a href="${paper.huggingface_link}" target="_blank" class="action-btn link-btn">
                                        <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M9 12l2 2 4-4"></path><circle cx="12" cy="12" r="10"></circle></svg> Hugging Face
                                    </a>` : ''}
                                    ${paper.aikosh_link ? `<a href="${paper.aikosh_link}" target="_blank" class="action-btn link-btn">
                                        <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M12 2L2 7l10 5 10-5-10-5zM2 17l10 5 10-5M2 12l10 5 10-5"></path></svg> AIKosh
                                    </a>` : ''}
                                </div>
                            </div>
                        `).join('')}
                    </div>
                </div>
            `;
        }

        // Global functions for buttons
        window.toggleAbstract = function (index) {
            const el = document.getElementById(`abstract-${index}`);
            if (el.style.display === 'none') {
                el.style.display = 'block';
            } else {
                el.style.display = 'none';
            }
        };

        window.copyCitation = function (index) {
            const paper = papersData[index];
            navigator.clipboard.writeText(paper.citation).then(() => {
                alert('Citation copied to clipboard!');
            });
        };

        // Data derived from public profile (Bento.me/MSR/GitHub)
        const cardsContent = {
            'PROJECTS': `
                <div class="content-section">
                    <h3>Technical Projects</h3>
                    <ul>
                        <li><strong>Kahani:</strong> A culturally-nuanced visual storytelling tool designed for non-western cultures, focusing on bridging the gap in AI representation.</li>
                        <li><strong>Stock Prediction Engine:</strong> A machine learning model designed to analyze market trends and predict stock performance with high accuracy.</li>
                        <li><strong>Rainfall Prediction System:</strong> Leveraged historical weather data to build predictive models for regional rainfall patterns.</li>
                        <li><strong>Image-to-Text Translation:</strong> Developed a multimodal system capable of converting visual information into descriptive text, enhancing accessibility.</li>
                    </ul>
                </div>
            `,
            'PAPERS': generatePapersHTML(),
            'WORK': `
                <div class="content-section">
                    <h3>Professional Experience</h3>
                    <ul>
                        <li><strong>Research Fellow @ Microsoft Research India:</strong> Currently working on cutting-edge problems in Natural Language Processing (NLP) and AI agents.</li>
                        <li><strong>Ex-PwC India:</strong> Gained valuable industry experience in technology consulting and implementation.</li>
                    </ul>
                </div>
            `,
            'SKILLS': `
                <div class="content-section">
                    <h3>Core Competencies</h3>
                    <ul>
                        <li><strong>AI & Machine Learning:</strong> Large Language Models (LLMs), Natural Language Processing (NLP), Multimodal AI.</li>
                        <li><strong>Research:</strong> Computational Social Science, Low-Resource NLP.</li>
                        <li><strong>Programming:</strong> Python, PyTorch, JavaScript, React.</li>
                    </ul>
                </div>
            `,
            'AI': `
                 <div class="content-section">
                    <h3>Artificial Intelligence Focus</h3>
                    <p>My work centers on the democratization of AI, specifically focusing on:</p>
                    <ul>
                        <li><strong>Low-Resource NLP:</strong> Making AI accessible for languages and cultures often underrepresented in mainstream datasets.</li>
                        <li><strong>AI Agents:</strong> Building autonomous systems capable of complex reasoning and task execution.</li>
                    </ul>
                </div>
            `,
            'BOOKS': `
                <div class="content-section">
                    <h3>Reading List</h3>
                    <p>Exploring the intersection of technology, sociology, and philosophy. <em>(Content to be populated)</em></p>
                </div>
            `,
            'MISC': `
                <div class="content-section">
                    <h3>Writes & Thoughts</h3>
                    <p>I actively write on <a href="https://medium.com/@deepthisudharsan" target="_blank">Medium</a> about:</p>
                    <ul>
                        <li>Unpacking the complexities of LLMs.</li>
                        <li>Experiences as a researcher in the fast-paced AI world.</li>
                        <li>Tutorials and insights on NLP techniques.</li>
                    </ul>
                </div>
            `
        };

        const contentDiv = document.getElementById('content');

        // Normalize key to handle case variations
        let matchedKey = Object.keys(cardsContent).find(k => titleKey.includes(k)) || 'DEFAULT';

        if (cardsContent[titleKey]) {
            contentDiv.innerHTML = cardsContent[titleKey];
        } else if (cardsContent[matchedKey] && matchedKey !== 'DEFAULT') {
            contentDiv.innerHTML = cardsContent[matchedKey];
        } else {
            // Default Fallback
            contentDiv.innerHTML = `
                <p>Welcome to the <strong>${titleDisplay}</strong> section. Here you will find detailed information, case studies, and resources related to this topic.</p>
                <p><em>(Detailed content for this section is currently being updated.)</em></p>
            `;
        }
    </script>
</body>

</html>